{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "from typing import List, Dict \n",
    "import dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, GPU was found and recognized!\n"
     ]
    }
   ],
   "source": [
    "# Don't continue if your gpu isnt recognized, it's gonna take too long\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Yes, GPU was found and recognized!\")\n",
    "else:\n",
    "    print(\"No, something went wrong. Make sure to install nvidia driver. :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step: Turn All Artists Into Their Own Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists: set = {artist_name for artist_name in os.listdir(\"data\") if os.path.isdir(f\"data/{artist_name}\")}\n",
    "data_frames: Dict[str, pd.DataFrame] = {}\n",
    "combined_song_strings: str = \"\"\n",
    "\n",
    "def artist_songs_to_data_frame(artist: str) -> tuple:\n",
    "    directory: str = f\"data/{artist}\"\n",
    "    df_rows: List[str, str] = []\n",
    "    artist_vocab: List[str] = []\n",
    "\n",
    "    for song_path in os.listdir(directory):\n",
    "        if len(song_path) <= 7 or song_path[:7] != \"edited_\":\n",
    "            continue\n",
    "\n",
    "        song_name: str = song_path[:len(song_path)-4]\n",
    "        song_stringified: str = \"\"\n",
    "        lyrics_list: List[str] = []\n",
    "        song_file: TextIOWrapper = open(f\"{directory}/{song_path}\") # type: ignore\n",
    "\n",
    "        for line in song_file:\n",
    "            song_stringified += line \n",
    "            \n",
    "            global combined_song_strings\n",
    "            combined_song_strings += line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                lyrics_list += line.split(\" \")\n",
    "\n",
    "        artist_vocab += lyrics_list\n",
    "        song_file.close()\n",
    "        df_rows.append((song_name, song_stringified, lyrics_list))\n",
    "\n",
    "    return pd.DataFrame(df_rows, columns=[\"Song_Name\", \"Song_String\", \"Lyrics_List\"]), sorted(list(set(artist_vocab)))\n",
    "\n",
    "for artist in artists:\n",
    "    # wanted to use the csv but life is pain :(, didn't have enough time\n",
    "    artist_tuple: tuple = artist_songs_to_data_frame(artist)\n",
    "    data_frames[artist] = artist_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Artist_LSTM_Model(nn.Module):\n",
    "    def __init__(self, corpus: list, hidden_dimensionality: int, embedding_dimensionality: int, dropout: int, num_layers: int):\n",
    "        super(Artist_LSTM_Model, self).__init__()\n",
    "        self.linear_module: nn.Linear = nn.Linear(hidden_dimensionality, corpus)\n",
    "        self.hidden_dimensionality: int = hidden_dimensionality\n",
    "        self.embeddings: nn.Embedding = nn.Embedding(corpus, embedding_dimensionality)\n",
    "        self.forward_function: nn.Linear = nn.Linear(hidden_dimensionality, corpus)\n",
    "        self.lstm: nn.lSTM = nn.LSTM(embedding_dimensionality, hidden_dimensionality, num_layers = num_layers, dropout=dropout)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        return self.forward_function(self.lstm(self.embeddings(seq_in.t()))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artist_model(artist_song_strings: list, window_size: int, steps: int, epochs: int, create_new_model=True) -> tuple:\n",
    "    def get_data(sentences: list, next_chars: list) -> tuple:\n",
    "        x: np.ndarray = np.zeros((len(sentences), window_size))\n",
    "        y: np.ndarray = np.zeros((len(sentences)))\n",
    "        \n",
    "        for i in range(len(sentences)):\n",
    "            sentence: str = sentences[i]\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[i, t] = char_converter[char]\n",
    "\n",
    "            y[i] = char_converter[next_chars[i]]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def create_model() -> Artist_LSTM_Model:\n",
    "        sentences: list = []\n",
    "        next_chars: list = []\n",
    "\n",
    "        for i in range(0, len(lines) - window_size, steps):\n",
    "            sentences.append(lines[i: i + window_size])  \n",
    "            next_chars.append(lines[i + window_size]) \n",
    "            \n",
    "        training_instances: tuple = get_data(np.array(sentences), np.array(next_chars))\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(training_instances[0], dtype=torch.long).to(device=\"cuda\"),\n",
    "            torch.tensor(training_instances[1], dtype=torch.long).to(device=\"cuda\")\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size = 256)\n",
    "\n",
    "        model: Artist_LSTM_Model = Artist_LSTM_Model(len(words),256,256, .5, 10)\n",
    "        model.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adamaz(model.parameters(), lr = 0.07, beta=(.9, .99)) \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for load in train_loader:\n",
    "                model(load[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()\n",
    "\n",
    "        return model\n",
    "\n",
    "    lines = re.findall(r'\\S+|\\n', re.sub(\"\\n\", \" \\n \", artist_song_strings.str.cat(sep='\\n').lower()))\n",
    "    words = sorted(list(set(lines)))\n",
    "\n",
    "    char_converter: dict = {}\n",
    "    integer_converter: dict = {}\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "        char_converter[word] = index \n",
    "        integer_converter[index] = word\n",
    "\n",
    "    return None if not create_new_model else create_model(),  integer_converter, char_converter\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(seed_lyrics: list, model: Artist_LSTM_Model, integer_convertor: list, char_convertor: list, num_of_chars: int, window_size: int, variance: float) -> str:\n",
    "    def calc_next_word(current_predictions: list, variance: float):\n",
    "        predictions: np.ndarray = np.log(np.asarray(current_predictions).astype('float64'))/variance\n",
    "        exponential_predictions: float = np.exp(predictions)\n",
    "\n",
    "        return np.argmax(np.random.multinomial(1, exponential_predictions/np.sum(exponential_predictions), 1))\n",
    "\n",
    "    generated_lyrics: str = \" \".join(seed_lyrics)\n",
    "    window: list = seed_lyrics\n",
    "\n",
    "    for i in range(num_of_chars):\n",
    "        x: np.ndarray = np.zeros((1, window_size))\n",
    "\n",
    "        for t, char in enumerate(window):\n",
    "            x[0, t] = char_convertor[char] \n",
    "            \n",
    "        x_in: Variable = Variable(torch.LongTensor(x).to(device=\"cuda\"))\n",
    "        pred: np.array = np.array(F.softmax(model(x_in), dim=1).data[0].cpu())\n",
    "\n",
    "        next_word: list = integer_convertor[calc_next_word(pred, variance)] \n",
    "        window: list = window[1:] + [next_word]\n",
    "         \n",
    "        generated_lyrics += \" \" + next_word \n",
    "        \n",
    "    return generated_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_seed_lyrics(seed_lyrics: list, artist_words: list, window_size: int) -> False:\n",
    "    if len(seed_lyrics) != window_size:\n",
    "        print(\"Seed lyric size is not the same as the window size\")\n",
    "        return False\n",
    "    \n",
    "    valid_seed_lyrics: bool = True \n",
    "    \n",
    "    for word in seed_lyrics:\n",
    "        if word not in artist_words and word != \"\\n\":\n",
    "            print(word, \"was not in artist word list\")\n",
    "            valid_seed_lyrics = False \n",
    "\n",
    "    return valid_seed_lyrics \n",
    "\n",
    "artists: dict = {\n",
    "    \"Eminem\": [\"shady\", \"\\n\", \"i\", \"am\", \"back\", \"\\n\", \"eminem\", \"wasnt\", \"the\", \"best\" ], \n",
    "    \"Kanye West\": [\"start\", \"\\n\", \"like\", \"im\", \"back\", \"at\", \"the\", \"start\", \"\\n\", \"here\"], \n",
    "    \"Tame Impala\": [\"my\", \"name\", \"is\", \"impala\", \"like\", \"the\", \"car\", \"but\", \"im\", \"that\"],\n",
    "    \"The Maine\": [\"from\", \"maine\", \"and\", \"thats\", \"my\", \"name\", \"\\n\", \"i\", \"dont\", \"eat\"],\n",
    "    \"Pink Floyd\": [\"car\", \"\\n\", \"i\", \"own\", \"a\", \"bar\", \"but\", \"not\", \"so\", \"far\"],\n",
    "    \"The Story So Far\": [\"far\", \"i\", \"have\", \"a\", \"car\", \"with\", \"the\", \"story\", \"so\", \"far\"]\n",
    "}\n",
    "\n",
    "window_size: int = 10\n",
    "steps: int = 1\n",
    "epochs: int = 100\n",
    "num_of_chars: int = 200\n",
    "variance: int = 1\n",
    "\n",
    "generated_lyrics_file = open(\"lstm_generated_lyrics.txt\", \"w\")\n",
    "\n",
    "for artist, seed_lyrics in artists.items():\n",
    "    if not check_seed_lyrics(seed_lyrics, data_frames[artist][1], window_size):\n",
    "        print(\"Could not generate lyrics for\", artist, \"fix errors above\")\n",
    "        continue\n",
    "\n",
    "    create_new_model: bool =  True if not f\"Eminem.pth\" in os.listdir(\"./lstm_models\") else False\n",
    "    data: tuple = create_artist_model(data_frames[artist][0][\"Song_String\"], window_size, steps, epochs, create_new_model)\n",
    "\n",
    "    model: Artist_LSTM_Model or None = data[0]\n",
    "    \n",
    "    if model is None:\n",
    "        model = torch.load(f\"./lstm_models/{artist}.pth\")\n",
    "    else:\n",
    "        torch.save(model, f\"./lstm_models/{artist}.pth\")\n",
    "\n",
    "    generated_lyrics_file.write(generate_lyrics(seed_lyrics, model, data[1], data[2], num_of_chars, window_size, variance) + \"\\n\\n\")\n",
    "\n",
    "generated_lyrics_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
